[2025-10-15 00:00 UTC]
Feature: Realtime voice call + nudges (verse)
- Backend: Added POST /api/realtime/token to mint ephemeral tokens via OpenAI Realtime sessions; prefers OPENAI_API_KEY.
- Backend: Added POST /api/nudges/generate to produce â‰¤3 concise nudges from recent transcript (gpt-3.5-turbo).
- Frontend: Removed LLMResponseBubble + polling; added CallProvider context for call lifecycle, transcript, nudges.
- Frontend: Added CallControls (Start/End) in ServicePageTabs header; added NudgesTray bottom-right for small cards.
- Frontend: Seed initial assistant line "Hi, I am looking for a deep cleaning service today." on call connect.
- Note: WebRTC flow uses ephemeral token -> SDP offer/answer with https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview, voice=verse.

[2025-10-16 PST]
Enhancement: Nudge System Optimization and Bug Fixes
- Issue Fixed: Removed duplicate NudgesTray component that was rendering in both App.tsx and ServicePageTabs.tsx
  * This was causing double polling of the backend and potential duplicate nudge displays
  * Now NudgesTray only renders globally in App.tsx (line 35)
  
- Enhancement: Increased nudge display persistence and visibility
  * Display time: Increased from 5 seconds to 15 seconds for better readability
  * Fade timing: Adjusted to start 1 second before removal (14s)
  * Visible nudges: Increased from 3 to 5 nudges shown simultaneously
  * Backlog size: Increased from 15 to 30 nudges for better persistence across call duration
  
- Enhancement: Added comprehensive logging to server-side nudge system
  * Added logging for transcript appends with turn count tracking
  * Added logging for nudge generation count
  * Added logging for pending nudges queue operations (add/serve/acknowledge)
  * Added logging for ACK operations with before/after counts
  * Improved error handling with descriptive error messages
  
- Technical Details:
  * NudgesTray (frontend) polls /api/nudges/latest every 600ms
  * Server auto-generates nudges via /api/transcript/append using GPT-3.5-turbo
  * Nudges stored in pendingNudges array with unique 'sid' identifiers
  * Client ACKs displayed nudges via /api/nudges/ack to prevent re-display
  * Deduplication by title (case-insensitive) across both CallContext and polling sources
  
- Files Modified:
  * src/pages/ServicePageTabs.tsx - Removed duplicate NudgesTray import and component
  * src/components/NudgesTray.tsx - Increased display time (15s), visibility (5 nudges), backlog (30)
  * server.ts - Added comprehensive logging for transcript, nudge generation, and ACK operations
  
- Testing Recommendations:
  * Start a call via the admin interface at http://localhost:3001/admin
  * Monitor server console for [Nudges], [Transcript] log messages
  * Verify nudges appear in bottom-right corner and persist for 15 seconds
  * Verify up to 5 nudges can be displayed simultaneously
  * Verify new nudges replace old ones smoothly as they expire

[2025-10-16 PST - Update 2]
Critical Fix: Nudge Generation During Active Calls
- Issue Fixed: Nudges only appeared at call start, not during ongoing conversation
  * Root cause: Data channel event handlers not capturing all OpenAI Realtime event types
  * Root cause: Aggressive deduplication preventing re-showing of relevant nudges
  
- Enhancement: Improved Data Channel Event Handling (server.ts admin page)
  * Added support for multiple OpenAI Realtime event types:
    - response.audio_transcript.delta
    - response.text.delta
    - response.done
    - conversation.item.created
    - conversation.item.completed
  * Added comprehensive event logging (all non-delta events logged)
  * Added error handling with descriptive messages
  * Added visual emojis (ðŸ‘¤ for user, ðŸ¤– for assistant) in logs
  
- Enhancement: Improved Speech Recognition
  * Added error handler for Speech Recognition failures
  * Added auto-restart on STT end event
  * Added empty string filtering to prevent invalid turns
  * Added "[STT] Started - speak now!" confirmation message
  
- Enhancement: Time-Based Deduplication (60-second cooldown)
  * Previous: Nudges with same title never re-shown (too aggressive)
  * New: Nudges can re-appear after 60 seconds
  * Implemented recentlyShownNudges Map to track shown nudge titles with timestamps
  * Auto-cleanup of old entries (older than 60 seconds)
  * Detailed logging: "Generated X nudges but all were filtered (duplicates or recently shown)"
  
- Enhancement: Real-Time Status Dashboard in Admin Page
  * Added 3 status indicators with green/gray color coding:
    - "STT: Active/Inactive" - Speech recognition status
    - "Transcript: X turns" - Total conversation turns captured
    - "Nudges: X pending" - Current pending nudges in queue
  * Status updates every 2 seconds automatically
  * Visual feedback when turns are successfully sent to server
  
- Technical Improvements:
  * Added createdAt timestamp to ServerNudge type
  * Enhanced logging with nudge titles in generation messages
  * Better filtering logic with clear console messages
  * Graceful error handling throughout event pipeline
  
- Files Modified:
  * server.ts (lines 91-236) - Complete rewrite of admin page event handling
  * server.ts (lines 361-367) - Added recentlyShownNudges Map
  * server.ts (lines 396-431) - Time-based deduplication logic
  * server.ts (lines 452-477) - ACK handler with recently shown tracking
  
- Debugging Commands:
  * Watch for turn capture: grep -E "ðŸ‘¤|ðŸ¤–" in admin page log
  * Watch for events: grep "\[Event\]" in admin page log
  * Watch for server processing: grep "\[Transcript\]\|\[Nudges\]" in server console
  * Check nudge generation: Look for "Generated X nudges" or "all were filtered"

[2025-10-16 PST - Update 3]
Enhancement: High-Quality Nudge Generation System
- Issue Addressed: Ensure nudges are meaningful, non-repetitive, and high-quality
  * Problem: Generic, repetitive suggestions like "offer more services" or "be helpful"
  * Problem: Same nudges appearing repeatedly despite different conversation contexts
  
- Enhancement: Complete Prompt Rewrite with Quality Standards
  * Changed from basic rules to comprehensive quality framework
  * Added GOOD vs BAD examples for each nudge type:
    - UPSELL: Specific service + value + concrete benefit
    - CROSS-SELL: Logical connection + bundling incentive + tangible outcome
    - TIP: Specific action + why it matters + strategic benefit
  * Strict quality requirements:
    - Must be IMMEDIATELY ACTIONABLE with clear next step
    - Include specific $ amounts, percentages, or timeframes
    - Focus on CUSTOMER VALUE (safety, savings, convenience)
    - Be conversational, not salesy or pushy
    - Context-aware: only suggest what makes sense
    
- Enhancement: Active Repetition Prevention
  * System now passes list of recently used titles to AI
  * Format: "AVOID THESE RECENTLY USED TITLES (generate NEW suggestions):"
  * Tracks last 20 shown nudges + current pending queue
  * AI explicitly instructed to generate NEW, different suggestions
  
- Enhancement: Quality Over Quantity
  * Reduced from 4 nudges to 3 maximum per turn
  * AI can return 0-1 nudges if conversation doesn't warrant quality suggestions
  * Prevents forcing generic nudges just to hit a count
  
- Technical Improvements:
  * Upgraded from gpt-3.5-turbo to gpt-4o-mini (better quality, still cost-effective)
  * Increased temperature from 0.2 to 0.3 for more creative, varied suggestions
  * Increased max_tokens from 300 to 400 for detailed responses
  * Enhanced logging: Shows generated nudge titles in console
  
- Example Quality Improvements:
  BEFORE (Generic):
  - "Add more services" 
  - "Offer upgrade"
  - "Ask about customer needs"
  
  AFTER (Specific & Valuable):
  - "Safety Inspection Bundle ($45)" â†’ "Identifies fire hazards & improves efficiency by 30%."
  - "HVAC Duct Cleaning" â†’ "Share ductwork with dryer. Bundle saves $50 & improves air quality."
  - "Ask: 'When last cleaned?'" â†’ "Reveals urgency. 3+ years = high fire risk angle."
  
- Files Modified:
  * server.ts (lines 426-480) - Auto-generation prompt with quality standards
  * server.ts (lines 354-431) - Standalone endpoint prompt (matching quality)
  * server.ts (lines 475-480) - Model upgrade to gpt-4o-mini
  
- Verification:
  * Check server console for: "[Nudges] Generated X high-quality nudges"
  * Verify nudges are specific with $ amounts or percentages
  * Confirm no generic "offer more services" type suggestions
  * Watch for variety across multiple conversation turns
